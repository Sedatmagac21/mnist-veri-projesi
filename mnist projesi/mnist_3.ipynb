{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5acde73-01cb-486e-9871-8f9158f5e84a",
   "metadata": {},
   "source": [
    "# Mnist veri seti ile müzik yapma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73006282-aa5d-4cff-8bda-14c837ab3f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import warnings\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7a7223-a485-42a9-b530-4a27fc6feda7",
   "metadata": {},
   "source": [
    "# Veri indirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9621720-26fc-4e70-9918-d9dbb35c2469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: (64000, 784)\n",
      "Training labels size: (64000,)\n",
      "Test dataset size: (16000, 784)\n",
      "Test labels size: (16000,)\n"
     ]
    }
   ],
   "source": [
    "mnist = fetch_openml('mnist_784')\n",
    "images = mnist.data.to_numpy().reshape((-1, 28, 28))\n",
    "\n",
    "num_random_images = 10000\n",
    "random_images = np.random.randint(0, 256, size=(num_random_images, 28, 28))\n",
    "\n",
    "combined_images = np.concatenate([images, random_images])\n",
    "combined_labels = np.concatenate([mnist.target.astype(int), np.full(num_random_images, -1)])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_images, combined_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], -1))\n",
    "X_test = X_test.reshape((X_test.shape[0], -1))\n",
    "\n",
    "print(\"Training dataset size:\", X_train.shape)\n",
    "print(\"Training labels size:\", y_train.shape)\n",
    "print(\"Test dataset size:\", X_test.shape)\n",
    "print(\"Test labels size:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92723dd5-19eb-469b-baa9-c08a90b4cc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: (64000, 784)\n",
      "Training labels size: (64000,)\n",
      "Test dataset size: (16000, 784)\n",
      "Test labels size: (16000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(combined_images, combined_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], -1))\n",
    "X_test = X_test.reshape((X_test.shape[0], -1))\n",
    "\n",
    "print(\"Training dataset size:\", X_train.shape)\n",
    "print(\"Training labels size:\", y_train.shape)\n",
    "print(\"Test dataset size:\", X_test.shape)\n",
    "print(\"Test labels size:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbd329fd-445f-4549-8319-1897ba60fba8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a054bf4a-fe31-418d-80ce-8680c291550a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import soundfile as sf\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45f57b7d-6160-4897-b513-d229e82c8231",
   "metadata": {},
   "outputs": [],
   "source": [
    "note_mapping = ['C', 'D', 'E', 'F', 'G', 'A', 'B', 'C#', 'D#', 'E#']\n",
    "note_frequencies = {'C': 261.63, 'C#': 277.18, 'D': 293.66, 'D#': 311.13, 'E': 329.63, 'E#': 349.23,\n",
    "                    'F': 349.23, 'G': 392.00, 'A': 440.00, 'B': 493.88}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fec4d57e-8e9f-495d-bedb-4817f00d30e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Çalınan notalar: ['F', 'C#', 'D#', 'E#', 'G', 'E', 'E', 'C', 'G', 'D']\n"
     ]
    }
   ],
   "source": [
    "melody = []\n",
    "for _ in range(10):\n",
    "    random_index = np.random.randint(0, len(x_test))\n",
    "    random_digit = y_test[random_index]\n",
    "    note = note_mapping[random_digit]\n",
    "    melody.append(note)\n",
    "\n",
    "print(\"Çalınan notalar:\", melody)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe7c5f65-c05a-4d71-b048-bec3a14cc185",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.concatenate([np.sin(2 * np.pi * note_frequencies[note] * np.linspace(0, 0.5, 22050, endpoint=False)) for note in melody])\n",
    "sf.write(\"melody.wav\", y, 44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6870f22b-1176-4f02-a190-32b2a962de13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
